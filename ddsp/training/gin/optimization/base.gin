# -*-Python-*-
import ddsp
import ddsp.training

# Globals for easier configuration with --gin_param
batch_size = 32

train.batch_size = %batch_size
train.num_steps = 1000000
train.steps_per_summary = 300
train.steps_per_save = 300

Trainer.learning_rate_g = 3e-4
Trainer.learning_rate_d = 6e-5
Trainer.lr_decay_steps = 40000
Trainer.lr_decay_rate = 0.98
Trainer.grad_clip_norm = 3.0
Trainer.checkpoints_to_keep = 10
Trainer.d_steps_per_g_steps = 4