{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from ddsp.colab import jupyter_utils\n",
    "import ddsp.training\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "TRAIN_TFRECORD_FILEPATTERN = os.environ.get(\"URMP_MONO\")\n",
    "data_provider = ddsp.training.data.TFRecordProvider(TRAIN_TFRECORD_FILEPATTERN)\n",
    "print(data_provider is ddsp.training.data.DataProvider)\n",
    "dataset = data_provider.get_batch(4)\n",
    "\n",
    "for i in iter(dataset):\n",
    "    for k, v in i.items():\n",
    "        print(k, v.shape)\n",
    "    break\n",
    "\n",
    "try:\n",
    "    ex = next(iter(dataset))\n",
    "except StopIteration:\n",
    "    raise ValueError(\n",
    "      'TFRecord contains no examples. Please try re-running the pipeline with '\n",
    "      'different audio file(s).')\n",
    "\n",
    "ex = next(iter(dataset))\n",
    "jupyter_utils.show_audio(ex['audio'][0])\n",
    "\n",
    "f, ax = plt.subplots(3, 1, figsize=(14, 4))\n",
    "x = np.linspace(0, 4.0, 1000)\n",
    "ax[0].set_ylabel('loudness_db')\n",
    "ax[0].plot(x, ex['loudness_db'][0])\n",
    "ax[1].set_ylabel('F0_Hz')\n",
    "ax[1].set_xlabel('seconds')\n",
    "\n",
    "ax[1].plot(x, ex['f0_hz'][0])\n",
    "ax[2].set_ylabel('F0_confidence')\n",
    "ax[2].set_xlabel('seconds')\n",
    "ax[2].plot(x, ex['f0_confidence'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "import tensorboard as tb\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import time\n",
    "\n",
    "import ddsp\n",
    "from ddsp.training import (data, decoders, encoders, models, preprocessing, \n",
    "                           train_util, trainers, discriminator)\n",
    "from ddsp.training.models.lsgan import LSGAN\n",
    "import gin\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow.compat.v2 as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from ddsp.synths import TensorToAudio\n",
    "\n",
    "gin.enter_interactive_mode()\n",
    "\n",
    "\n",
    "\n",
    "SAVE_DIR = \"artifacts/tmp\"\n",
    "\n",
    "# tb.notebook.start('--logdir \"{}\"'.format(SAVE_DIR))\n",
    "\n",
    "sample_rate = 16000\n",
    "n_samples = 4*sample_rate\n",
    "\n",
    "strategy = train_util.get_strategy()\n",
    "\n",
    "with strategy.scope():\n",
    "    TIME_STEPS = 1000\n",
    "\n",
    "    # Create Neural Networks.\n",
    "    preprocessor = preprocessing.F0LoudnessPreprocessor(time_steps=TIME_STEPS)\n",
    "\n",
    "    decoder = decoders.UntitledGAN(input_keys = ('ld_scaled', 'f0_hz', 'z'))\n",
    "\n",
    "    # Create ProcessorGroup.\n",
    "    dag = [(TensorToAudio(), ['audio_tensor'])]\n",
    "\n",
    "    processor_group = ddsp.processors.ProcessorGroup(dag=dag,\n",
    "                                                    name='processor_group')\n",
    "\n",
    "\n",
    "    # Loss_functions\n",
    "    spectral_loss = ddsp.losses.SpectralLoss(loss_type='L1',\n",
    "                                            mag_weight=1.0,\n",
    "                                            logmag_weight=1.0)\n",
    "    \n",
    "    encoder = encoders.MfccTimeConstantRnnEncoder(rnn_channels = 512, rnn_type = 'gru', z_dims = 16, z_time_steps = 125)\n",
    "    \n",
    "    critic = discriminator.ParallelWaveGANDiscriminator(input_keys=['discriminator_audio', 'f0_hz', 'loudness_db'])\n",
    "    model = LSGAN(preprocessor=preprocessor,\n",
    "                                encoder=encoder,\n",
    "                                decoder=decoder,\n",
    "                                processor_group=processor_group,\n",
    "                                discriminator=critic,\n",
    "                                losses=[spectral_loss])\n",
    "    trainer = trainers.Trainer(model, strategy, checkpoints_to_keep=1)\n",
    "    dataset = trainer.distribute_dataset(dataset)\n",
    "    trainer.build(next(iter(dataset)))\n",
    "    dataset_iter = iter(dataset)\n",
    "    \n",
    "    for i in range(10):\n",
    "        losses = trainer.train_step(dataset_iter)\n",
    "        res_str = 'step: {}\\t'.format(i)\n",
    "        for k, v in losses.items():\n",
    "            res_str += '{}: {:.2f}\\t'.format(k, v)\n",
    "        print(res_str)\n",
    "\n",
    "        if i % 300 == 1:\n",
    "            print(f\"Step {i}\")\n",
    "            trainer.save(SAVE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = next(dataset_iter)\n",
    "noise = model(ex)\n",
    "jupyter_utils.show_audio(noise['audio_synth'][3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
